@Article{marjoramMarkovChainMonte2003,
  title = {Markov Chain {{Monte Carlo}} without Likelihoods},
  author = {P. Marjoram and J. Molitor and V. Plagnol and S. Tavare},
  date = {2003-12-23},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proceedings of the National Academy of Sciences},
  volume = {100},
  pages = {15324--15328},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0306899100},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0306899100},
  urldate = {2020-08-17},
  file = {/Users/anubhav/Zotero/storage/9ACK9F3R/Marjoram et al. - 2003 - Markov chain Monte Carlo without likelihoods.pdf},
  langid = {english},
  number = {26},
}

@Article{gelmanInferenceIterativeSimulation1992,
  title = {Inference from {{Iterative Simulation Using Multiple Sequences}}},
  author = {Andrew Gelman and Donald B. Rubin},
  date = {1992-11},
  journaltitle = {Statistical Science},
  shortjournal = {Statist. Sci.},
  volume = {7},
  pages = {457--472},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1177011136},
  url = {https://projecteuclid.org/euclid.ss/1177011136},
  urldate = {2020-12-20},
  abstract = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
  file = {/Users/anubhav/Zotero/storage/RXQXT4TP/Gelman and Rubin - 1992 - Inference from Iterative Simulation Using Multiple.pdf},
  keywords = {Bayesian inference,convergence of stochastic processes,ECM,EM,Gibbs sampler,importance sampling,Metropolis algorithm,multiple imputation,random-effects model,SIR},
  langid = {english},
  number = {4},
  zmnumber = {06853057},
}
